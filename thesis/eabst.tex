To recommend reading materials to users based on their language competence, the system needs to be able to estimate the difficulty of reading in correspondence to the user. The difficulty is typically estimated through a large amount of pre-test. However, it requires much effort from users, which is not applicable to a large-scale user reading applications. Our approach does not rely on the pre-test, instead, adopts relative difficulty, which is the percentage of unknown words in materials and can be estimated at runtime by monitoring user-system interactions. The original relative difficulty, which assumes that all unknown words are marked, however unintentional or miss clicks may exist in the runtime estimation. To further improve the estimation of relative difficulty, this thesis proposes weighted relative difficulty based on word importance to mitigate the effect of human errors. This thesis also devise a collaborative filtering-based algorithm to estimate the weighted relative difficulty. We evaluate our method through a case study with 328 users, and results show that estimation based on our weighted relative difficulty is more accurate than the one based on original relative difficulty.