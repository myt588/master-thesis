{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from surprise import SVD\n",
    "from surprise import SVDpp\n",
    "from surprise import NMF\n",
    "from surprise import SlopeOne\n",
    "from surprise import CoClustering\n",
    "from surprise import KNNBasic\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import KNNWithZScore\n",
    "from surprise import KNNBaseline\n",
    "from surprise import NormalPredictor\n",
    "from surprise import BaselineOnly\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def percentCorrect(prediction, ground_truth, bound):\n",
    "    in_bound = 0\n",
    "    for index, x in enumerate(prediction):\n",
    "        if (x <= ground_truth[index] + bound and x >= ground_truth[index] - bound):\n",
    "            in_bound = in_bound + 1\n",
    "    return in_bound/len(prediction)\n",
    "\n",
    "rec_df = pd.read_csv('sentences-user-actions.csv')\n",
    "rec_df = rec_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "rec_df.head()\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(rec_df[['user_id', 'sentence_id', 'relative_difficulty']], reader)\n",
    "\n",
    "algos = [\n",
    "    SVD(),\n",
    "    SVDpp(), \n",
    "#     NMF(), #predicts 0 most of the times\n",
    "    KNNBasic(), \n",
    "    KNNWithMeans(), \n",
    "    KNNWithZScore(), \n",
    "    KNNBaseline(), \n",
    "    NormalPredictor(), \n",
    "    BaselineOnly(),\n",
    "#     CoClustering(), #predict all 0, the RMSE is 0.0252\n",
    "    SlopeOne()\n",
    "]\n",
    "\n",
    "for algo in algos:\n",
    "    # We can now use this dataset as we please, e.g. calling cross_validate\n",
    "    trainset, testset = train_test_split(data, test_size=.25)\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    accuracy.rmse(predictions)\n",
    "    accuracy.fcp(predictions)\n",
    "    truth = []\n",
    "    preds = []\n",
    "    truth_count = []\n",
    "    preds_count = []\n",
    "    for i in range(0, len(predictions)):\n",
    "#         print(predictions[i].r_ui, predictions[i].est)\n",
    "        row = rec_df.loc[(rec_df['user_id'] == predictions[i].uid) & (rec_df['sentence_id'] == predictions[i].iid)]\n",
    "        preds_count.append(row.iloc[0]['unique_word_count'] * predictions[i].est)\n",
    "        truth_count.append(row.iloc[0]['unknown_count'])\n",
    "        truth.append(predictions[i].r_ui)\n",
    "        preds.append(predictions[i].est)\n",
    "    r2 = r2_score(preds, truth)\n",
    "    interval = percentCorrect(preds_count, truth_count, 1)\n",
    "    print('percent interval: ' + str(interval))\n",
    "#     print('coefficient of determination: ' + str(r2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
